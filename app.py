"""
DebateFin: A trustworthy LLM-based multi-agent system for enterprise fundamental analysis


Core architecture:
- LLM: DeepSeek Chat API (via ChatOpenAI, compatible with OpenAI format)
- Framework: LangGraph for stateful multi-agent graph with debate loop
- Agents: Supervisor, Analyst, Risk, Trader, Judge (5 agents)
- Tools: yfinance, PyTorch LSTM, pandas, HuggingFace, VectorBT
"""

import streamlit as st
import os
import json
from typing import TypedDict, List, Dict, Any, Annotated
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # Non-interactive backend for Streamlit
import seaborn as sns
from io import BytesIO
import base64

# Plotly for interactive charts
try:
    import plotly.graph_objects as go
    import plotly.express as px
    from plotly.subplots import make_subplots
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

# LangChain imports
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver

# DeepSeek API support
import os

# Financial data and analysis
import yfinance as yf
import torch
import torch.nn as nn
from transformers import pipeline as hf_pipeline

# Backtesting
try:
    import vectorbt as vbt
    VBT_AVAILABLE = True
except ImportError:
    VBT_AVAILABLE = False
    # Note: st.warning() cannot be called at module level, will handle in main()

# Report generation (ä½¿ç”¨ HTMLï¼Œé›¶ä¾èµ–ï¼ŒStreamlit Cloud åŸç”Ÿæ”¯æŒ)
# Import custom modules
from tools import (
    fetch_stock_data, calculate_financial_metrics, 
    predict_growth_lstm, analyze_sentiment_hf, backtest_strategy,
    get_price_history  # ç¼“å­˜çš„ä»·æ ¼å†å²å‡½æ•°
)
from models import LSTMGrowthPredictor
from report_generator import generate_html_report_bytes
from cache_utils import cached_with_retry, clear_cache
from hallucination_checker import hallucination_checker
from guardrail_validator import guardrail_validator
from ppo_router import ppo_router
import re  # For regex in guardrail and judge agent

# ============================================================================
# Configuration
# ============================================================================

# Initialize session state
if 'conversation_history' not in st.session_state:
    st.session_state.conversation_history = []
if 'debate_logs' not in st.session_state:
    st.session_state.debate_logs = []
if 'current_analysis' not in st.session_state:
    st.session_state.current_analysis = None
if 'ablation_results' not in st.session_state:
    st.session_state.ablation_results = {}  # Store with/without debate results
if 'hallucination_checks' not in st.session_state:
    st.session_state.hallucination_checks = []

# Streamlit page config
st.set_page_config(
    page_title="DebateFin - Multi-Agent Financial Analysis",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# LangGraph State Definition
# ============================================================================

class DebateState(TypedDict):
    """State for multi-agent debate system with hierarchical structure"""
    messages: Annotated[List[Any], add_messages]
    ticker: str
    query: str
    round: int
    max_rounds: int
    # L1: Fundamental Analysis Layer (Analyst â†” Risk)
    analyst_evidence: Dict[str, Any]
    risk_flags: List[str]
    l1_debate_log: List[Dict[str, Any]]  # Analyst â†” Risk debate
    # L2: Trading Layer (Trader synthesis)
    trader_prediction: Dict[str, Any]
    l2_synthesis: str  # Trader synthesis of L1
    # L3: Judgment Layer (Judge backtest-guided scoring)
    judge_score: Dict[str, Any]  # Judge agent backtest-guided scoring
    backtest_result: Dict[str, Any]  # Backtest results
    # Overall
    debate_log: List[Dict[str, Any]]
    final_synthesis: str
    use_debate: str  # Ablation toggle: "debate" | "no_debate" | "single_agent"
    metrics: Dict[str, float]  # For ablation comparison (Sharpe, MAE, etc.)
    hallucination_check: Dict[str, Any]  # Hallucination check results
    tool_calls: List[Dict[str, Any]]  # Track all tool calls for guardrail
    validation_results: List[Dict[str, Any]]  # Guardrail validation results

# ============================================================================
# Agent Definitions
# ============================================================================

def get_llm(temperature=0.7):
    """
    Initialize LLM with DeepSeek API only
    ä»…ä½¿ç”¨ DeepSeek APIï¼Œä¸ä½¿ç”¨ OpenAI
    """
    # åªä½¿ç”¨ DeepSeek API Key
    api_key = st.secrets.get("DEEPSEEK_API_KEY", os.getenv("DEEPSEEK_API_KEY", ""))
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ç¤ºä¾‹å¯†é’¥
    if api_key and ("your-deepseek-api-key" in api_key.lower() or "your-actual" in api_key.lower() or api_key == "sk-your-deepseek-api-key-here"):
        st.error("""
        âŒ **æ£€æµ‹åˆ°ç¤ºä¾‹å¯†é’¥ï¼Œè¯·ä½¿ç”¨çœŸå®å¯†é’¥ï¼**
        
        ä½ çš„ `.streamlit/secrets.toml` æ–‡ä»¶ä¸­ä½¿ç”¨çš„æ˜¯ç¤ºä¾‹å¯†é’¥ï¼Œä¸æ˜¯çœŸå®çš„ DeepSeek API å¯†é’¥ã€‚
        
        **ç«‹å³ä¿®å¤**ï¼š
        1. æ‰“å¼€ `.streamlit/secrets.toml` æ–‡ä»¶
        2. å°† `DEEPSEEK_API_KEY = "sk-your-deepseek-api-key-here"` 
           æ›¿æ¢ä¸ºä½ çš„çœŸå®å¯†é’¥ï¼š`DEEPSEEK_API_KEY = "sk-ä½ çš„çœŸå®å¯†é’¥"`
        3. ä¿å­˜æ–‡ä»¶
        4. **é‡å¯ Streamlit åº”ç”¨**ï¼ˆå¿…é¡»é‡å¯ï¼ï¼‰
        
        **è·å–çœŸå®å¯†é’¥**ï¼š
        - è®¿é—®: https://platform.deepseek.com/
        - ç™»å½•åï¼Œåœ¨æ§åˆ¶å°åˆ›å»º API å¯†é’¥
        - å¤åˆ¶çœŸå®çš„å¯†é’¥ï¼ˆä»¥ `sk-` å¼€å¤´ï¼‰
        """)
        return None
    
    if not api_key:
        st.error("""
        âš ï¸ **DeepSeek APIå¯†é’¥æœªé…ç½®**
        
        è¯·è®¾ç½® DeepSeek API å¯†é’¥ï¼Œæ–¹æ³•å¦‚ä¸‹ï¼š
        
        **æ–¹æ³•1: Streamlit Secretsï¼ˆæ¨èï¼‰**
        1. ç¼–è¾‘ `.streamlit/secrets.toml` æ–‡ä»¶
        2. æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š
        ```toml
        DEEPSEEK_API_KEY = "sk-your-actual-deepseek-api-key-here"
        DEEPSEEK_API_BASE = "https://api.deepseek.com"
        DEEPSEEK_MODEL = "deepseek-chat"
        ```
        
        **æ–¹æ³•2: ç¯å¢ƒå˜é‡**
        ```bash
        export DEEPSEEK_API_KEY="sk-your-actual-deepseek-api-key-here"
        export DEEPSEEK_API_BASE="https://api.deepseek.com"
        export DEEPSEEK_MODEL="deepseek-chat"
        ```
        
        **è·å– DeepSeek API å¯†é’¥**ï¼š
        - è®¿é—®: https://platform.deepseek.com/
        - æ³¨å†Œè´¦å·åï¼Œåœ¨æ§åˆ¶å°åˆ›å»º API å¯†é’¥
        """)
        return None
    
    # æ£€æŸ¥APIå¯†é’¥æ ¼å¼ï¼ˆåŸºæœ¬éªŒè¯ï¼‰
    if api_key and len(api_key) < 10:
        st.warning("âš ï¸ APIå¯†é’¥æ ¼å¼å¯èƒ½ä¸æ­£ç¡®ï¼Œè¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦å®Œæ•´")
    
    # DeepSeek APIé…ç½®ï¼ˆå¿…é¡»é…ç½®ï¼‰
    model_name = st.secrets.get("DEEPSEEK_MODEL", os.getenv("DEEPSEEK_MODEL", "deepseek-chat"))
    
    # å¼ºåˆ¶ç¡®ä¿ base_url æŒ‡å‘ DeepSeekï¼ˆç»å¯¹ä¸èƒ½æŒ‡å‘ OpenAIï¼‰
    # DeepSeek API endpoint å›ºå®šä¸º https://api.deepseek.com
    base_url = "https://api.deepseek.com"
    
    # éªŒè¯ API key æ ¼å¼
    if not api_key.startswith("sk-"):
        st.error(f"""
        âŒ **API å¯†é’¥æ ¼å¼é”™è¯¯**
        
        ä½ çš„ API å¯†é’¥: {api_key[:10]}...ï¼ˆå·²éšè—ï¼‰
        
        DeepSeek API å¯†é’¥å¿…é¡»ä»¥ "sk-" å¼€å¤´ã€‚
        è¯·æ£€æŸ¥ `.streamlit/secrets.toml` ä¸­çš„ `DEEPSEEK_API_KEY` æ˜¯å¦æ­£ç¡®ã€‚
        """)
        return None
    
    try:
        # ä½¿ç”¨ ChatOpenAIï¼Œå¼ºåˆ¶æŒ‡å®š DeepSeek çš„ base_url
        # DeepSeek API å…¼å®¹ OpenAI æ ¼å¼ï¼Œä½†å¿…é¡»æŒ‡å®šæ­£ç¡®çš„ base_url
        llm = ChatOpenAI(
            model=model_name,
            temperature=temperature,
            api_key=api_key,
            base_url=base_url,  # å¼ºåˆ¶ä½¿ç”¨ DeepSeek API endpoint: https://api.deepseek.com
            timeout=60,
            max_retries=2
        )
        return llm
    except Exception as e:
        error_msg = str(e)
        
        # æ˜¾ç¤ºå®é™…ä½¿ç”¨çš„é…ç½®ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰
        api_key_preview = api_key[:10] + "..." if len(api_key) > 10 else "***"
        
        if "401" in error_msg or "authentication" in error_msg.lower() or "invalid" in error_msg.lower():
            st.error(f"""
            âŒ **DeepSeek API è®¤è¯å¤±è´¥**
            
            **é”™è¯¯ä¿¡æ¯**: {error_msg}
            
            **å½“å‰é…ç½®**:
            - API Key: {api_key_preview}
            - Base URL: {base_url}
            - Model: {model_name}
            
            **å¯èƒ½çš„åŸå› **ï¼š
            1. âŒ DeepSeek API å¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ
            2. âŒ API å¯†é’¥æ ¼å¼ä¸æ­£ç¡®ï¼ˆå¿…é¡»ä»¥ `sk-` å¼€å¤´ï¼‰
            3. âŒ API å¯†é’¥æƒé™ä¸è¶³
            4. âŒ å¯†é’¥åœ¨ `.streamlit/secrets.toml` ä¸­é…ç½®é”™è¯¯
            
            **ç«‹å³æ£€æŸ¥**ï¼š
            1. âœ… æ‰“å¼€ `.streamlit/secrets.toml` æ–‡ä»¶
            2. âœ… ç¡®è®¤ `DEEPSEEK_API_KEY` çš„å€¼æ˜¯ä½ çš„çœŸå®å¯†é’¥ï¼ˆä¸æ˜¯ç¤ºä¾‹å¯†é’¥ï¼‰
            3. âœ… ç¡®è®¤å¯†é’¥ä»¥ `sk-` å¼€å¤´
            4. âœ… è®¿é—® https://platform.deepseek.com/ éªŒè¯å¯†é’¥æ˜¯å¦æœ‰æ•ˆ
            5. âœ… é‡å¯ Streamlit åº”ç”¨ï¼ˆä¿®æ”¹ secrets.toml åéœ€è¦é‡å¯ï¼‰
            
            **é…ç½®ç¤ºä¾‹**ï¼š
            ```toml
            DEEPSEEK_API_KEY = "sk-your-real-deepseek-api-key-here"
            DEEPSEEK_API_BASE = "https://api.deepseek.com"
            DEEPSEEK_MODEL = "deepseek-chat"
            ```
            
            âš ï¸ **é‡è¦**: ä¸è¦ä½¿ç”¨ `.streamlit/secrets.toml.example` ä¸­çš„ç¤ºä¾‹å¯†é’¥ï¼
            """)
        else:
            st.error(f"""
            âŒ **DeepSeek LLM åˆå§‹åŒ–å¤±è´¥**
            
            é”™è¯¯ä¿¡æ¯: {error_msg}
            
            å½“å‰é…ç½®:
            - Base URL: {base_url}
            - Model: {model_name}
            """)
        return None

def analyst_agent(state: DebateState) -> DebateState:
    """Analyst Agent: Extract financial metrics and evidence with tool-forced grounding"""
    llm = get_llm(temperature=0.3)
    if not llm:
        return state
    
    ticker = state["ticker"]
    query = state["query"]
    
    # TOOL-FORCED GROUNDING: Must call tools before reasoning
    # Track tool calls for guardrail validation
    tool_calls = []
    
    try:
        # Fetch real data using tools (cached with retry)
        try:
            stock_data = fetch_stock_data(ticker)
        except Exception as e:
            # ç»Ÿä¸€å¤„ç†æ•°æ®è·å–å¤±è´¥çš„é”™è¯¯ï¼ˆåªæ˜¾ç¤ºä¸€æ¬¡ï¼‰
            error_msg = str(e)
            if "æ•°æ®è·å–å¤±è´¥" in error_msg or "æ— æ³•ä»ä»»ä½•æ•°æ®æºè·å–" in error_msg:
                st.error(f"âŒ æ— æ³•è·å–è‚¡ç¥¨ {ticker} çš„æ•°æ®ï¼Œæ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥äº†ã€‚è¯·ç¨åå†è¯•æˆ–æ¢è‚¡ç¥¨ä»£ç ã€‚")
            else:
                st.error(f"âŒ æ•°æ®è·å–å¤±è´¥: {error_msg}")
            # è¿”å›ç©ºæ•°æ®ï¼Œé¿å…åç»­å¤„ç†å´©æºƒ
            stock_data = {"history": pd.DataFrame(), "info": {}, "ticker": ticker, "error": error_msg}
        
        tool_calls.append({
            "tool": "fetch_stock_data",
            "input": {"ticker": ticker},
            "result": {"success": True, "data_points": len(stock_data.get("history", []))}
        })
        
        metrics = calculate_financial_metrics(stock_data)
        tool_calls.append({
            "tool": "calculate_financial_metrics",
            "input": {"ticker": ticker},
            "result": {"metrics_count": len(metrics), "metrics": metrics}
        })
        
        # Register tool data for hallucination checking
        hallucination_checker.register_tool_data(ticker, "financial_metrics", metrics)
        hallucination_checker.register_tool_data(ticker, "stock_data", stock_data)
        
        # Get analyst reasoning with tool call annotation
        data_source = stock_data.get("data_source", "yfinance")
        tool_call_annotation = f"""<tool_call>
å·²è°ƒç”¨å·¥å…·:
1. fetch_stock_data({ticker}) - è·å–è‚¡ç¥¨æ•°æ®ï¼ˆæ•°æ®æº: {data_source}ï¼‰
2. calculate_financial_metrics() - è®¡ç®—è´¢åŠ¡æŒ‡æ ‡

å·¥å…·è¿”å›çš„å…³é”®æŒ‡æ ‡:
{json.dumps(metrics, indent=2, ensure_ascii=False)}
</tool_call>

"""
        
        prompt = f"""{tool_call_annotation}ä½ æ˜¯ä¸€ä½èµ„æ·±è´¢åŠ¡åˆ†æå¸ˆï¼ˆL1å±‚ï¼‰ã€‚åŸºäºä¸Šè¿°å·¥å…·è·å–çš„çœŸå®æ•°æ®ï¼Œåˆ†æè‚¡ç¥¨ä»£ç  {ticker} çš„è´¢åŠ¡æ•°æ®ã€‚

ç”¨æˆ·æŸ¥è¯¢: {query}

è¯·æä¾›:
1. å…³é”®è´¢åŠ¡æŒ‡æ ‡åˆ†æï¼ˆROEã€ROAã€æ¯›åˆ©ç‡ç­‰ï¼‰- å¿…é¡»å¼•ç”¨å·¥å…·è¿”å›çš„å…·ä½“æ•°å­—
2. è´¢åŠ¡å¥åº·çŠ¶å†µè¯„ä¼°
3. æ”¯æŒä½ ç»“è®ºçš„å…·ä½“è¯æ® - å¿…é¡»åŸºäºå·¥å…·æ•°æ®

ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒä¸“ä¸šå’Œå®¢è§‚ã€‚"""
        
        response = llm.invoke([HumanMessage(content=prompt)])
        
        # Guardrail validation: enforce tool call requirement
        validated_message = guardrail_validator.enforce_tool_call(
            "Analyst", response.content, tool_calls
        )
        
        # Hallucination check
        hallucination_result = hallucination_checker.check_hallucination(
            validated_message, ticker, ["financial_metrics"]
        )
        
        # Validation result
        is_valid, validation_result = guardrail_validator.validate_agent_message(
            "Analyst", validated_message, tool_calls
        )
        
        evidence = {
            "metrics": metrics,
            "analysis": validated_message,
            "timestamp": datetime.now().isoformat(),
            "hallucination_check": hallucination_result,
            "tool_calls": tool_calls,
            "validation": validation_result
        }
        
        state["analyst_evidence"] = evidence
        state["hallucination_check"] = hallucination_result
        state["tool_calls"] = state.get("tool_calls", []) + tool_calls
        state["validation_results"] = state.get("validation_results", []) + [validation_result]
        
        # L1 Debate log (Analyst â†” Risk)
        l1_entry = {
            "round": state["round"],
            "layer": "L1",
            "agent": "Analyst",
            "action": "evidence_extraction",
            "content": validated_message[:500] + "...",
            "hallucination_check": hallucination_result,
            "validation": validation_result,
            "tool_calls": tool_calls
        }
        state["l1_debate_log"] = state.get("l1_debate_log", []) + [l1_entry]
        state["debate_log"] = state.get("debate_log", []) + [l1_entry]
        
        # Store hallucination check in session state
        st.session_state.hallucination_checks.append({
            "agent": "Analyst",
            "round": state["round"],
            "check": hallucination_result
        })
    except Exception as e:
        state["analyst_evidence"] = {"error": str(e)}
        state["debate_log"].append({
            "round": state["round"],
            "agent": "Analyst",
            "action": "error",
            "content": f"æ•°æ®è·å–å¤±è´¥: {str(e)}"
        })
    
    return state

def risk_agent(state: DebateState) -> DebateState:
    """Risk Agent: Analyze sentiment and risk factors with tool-forced grounding"""
    llm = get_llm(temperature=0.4)
    if not llm:
        return state
    
    ticker = state["ticker"]
    query = state["query"]
    analyst_evidence = state.get("analyst_evidence", {})
    
    # TOOL-FORCED GROUNDING: Must call sentiment tool before reasoning
    try:
        # Sentiment analysis using HuggingFace (cached with retry)
        sentiment_score = analyze_sentiment_hf(ticker)
        
        # Register tool data
        hallucination_checker.register_tool_data(ticker, "sentiment", {"score": sentiment_score})
        
        # Risk assessment
        prompt = f"""ä½ æ˜¯ä¸€ä½é£é™©ç®¡ç†ä¸“å®¶ã€‚è¯„ä¼°è‚¡ç¥¨ä»£ç  {ticker} çš„é£é™©å› ç´ ã€‚

ç”¨æˆ·æŸ¥è¯¢: {query}

åˆ†æå¸ˆæä¾›çš„è¯æ®:
{json.dumps(analyst_evidence.get('analysis', ''), ensure_ascii=False)[:1000]}

å¸‚åœºæƒ…ç»ªå¾—åˆ†: {sentiment_score}

è¯·è¯†åˆ«:
1. ä¸»è¦é£é™©å› ç´ ï¼ˆè´¢åŠ¡é£é™©ã€å¸‚åœºé£é™©ã€è¡Œä¸šé£é™©ï¼‰
2. é£é™©ç­‰çº§ï¼ˆä½/ä¸­/é«˜ï¼‰
3. éœ€è¦è­¦æƒ•çš„ä¿¡å·

ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒè°¨æ…å’Œå®¢è§‚ã€‚"""
        
        response = llm.invoke([HumanMessage(content=prompt)])
        
        # Extract risk flags
        risk_flags = []
        if "é«˜" in response.content or "é£é™©" in response.content:
            risk_flags.append("é«˜é£é™©ä¿¡å·")
        if sentiment_score < 0.3:
            risk_flags.append("å¸‚åœºæƒ…ç»ªæ‚²è§‚")
        
        state["risk_flags"] = risk_flags
        state["debate_log"].append({
            "round": state["round"],
            "agent": "Risk",
            "action": "risk_assessment",
            "content": response.content[:500] + "...",
            "sentiment_score": sentiment_score
        })
    except Exception as e:
        state["risk_flags"] = [f"é£é™©è¯„ä¼°é”™è¯¯: {str(e)}"]
        state["debate_log"].append({
            "round": state["round"],
            "agent": "Risk",
            "action": "error",
            "content": str(e)
        })
    
    return state

def trader_agent(state: DebateState) -> DebateState:
    """Trader Agent: Make predictions and investment recommendations"""
    llm = get_llm(temperature=0.5)
    if not llm:
        return state
    
    ticker = state["ticker"]
    query = state["query"]
    analyst_evidence = state.get("analyst_evidence", {})
    risk_flags = state.get("risk_flags", [])
    
    try:
        # LSTM growth prediction
        metrics = analyst_evidence.get("metrics", {})
        growth_prediction = predict_growth_lstm(ticker, metrics)
        
        # Investment recommendation
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±äº¤æ˜“å‘˜å’ŒæŠ•èµ„é¡¾é—®ã€‚åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œæä¾›æŠ•èµ„å»ºè®®ã€‚

è‚¡ç¥¨ä»£ç : {ticker}
ç”¨æˆ·æŸ¥è¯¢: {query}

åˆ†æå¸ˆè¯æ®:
{json.dumps(analyst_evidence.get('analysis', ''), ensure_ascii=False)[:1000]}

é£é™©æ ‡å¿—: {', '.join(risk_flags) if risk_flags else 'æ— é‡å¤§é£é™©æ ‡å¿—'}

å¢é•¿é¢„æµ‹: {json.dumps(growth_prediction, ensure_ascii=False)}

è¯·æä¾›:
1. 2026å¹´ROEé¢„æµ‹ï¼ˆå¦‚æœç›¸å…³ï¼‰
2. æŠ•èµ„å»ºè®®ï¼ˆä¹°å…¥/æŒæœ‰/å–å‡ºï¼‰
3. ç›®æ ‡ä»·ä½åŒºé—´
4. æŠ•èµ„é€»è¾‘å’Œç†ç”±

ç”¨ä¸­æ–‡å›ç­”ï¼Œç»™å‡ºæ˜ç¡®çš„æŠ•èµ„å»ºè®®ã€‚"""
        
        response = llm.invoke([HumanMessage(content=prompt)])
        
        # Extract recommendation
        recommendation = "æŒæœ‰"
        if "ä¹°å…¥" in response.content or "ä¹°" in response.content:
            recommendation = "ä¹°å…¥"
        elif "å–å‡º" in response.content or "å–" in response.content:
            recommendation = "å–å‡º"
        
        prediction = {
            "recommendation": recommendation,
            "reasoning": response.content,
            "growth_prediction": growth_prediction,
            "timestamp": datetime.now().isoformat()
        }
        
        state["trader_prediction"] = prediction
        state["debate_log"].append({
            "round": state["round"],
            "agent": "Trader",
            "action": "prediction",
            "content": response.content[:500] + "...",
            "recommendation": recommendation
        })
    except Exception as e:
        state["trader_prediction"] = {"error": str(e)}
        state["debate_log"].append({
            "round": state["round"],
            "agent": "Trader",
            "content": str(e)
        })
    
    return state

def judge_agent(state: DebateState) -> DebateState:
    """
    Judge Agent (L3): Backtest-guided scoring and final decision
    Uses historical Sharpe ratio as reward signal (Backtest-Guided Router innovation)
    """
    llm = get_llm(temperature=0.4)
    if not llm:
        return state
    
    ticker = state["ticker"]
    trader_prediction = state.get("trader_prediction", {})
    recommendation = trader_prediction.get("recommendation", "æŒæœ‰")
    
    # TOOL-FORCED GROUNDING: Must run backtest before judgment
    tool_calls = []
    
    try:
        # Run backtest (tool call)
        backtest_result = backtest_strategy(ticker, strategy="sma")
        tool_calls.append({
            "tool": "backtest_strategy",
            "input": {"ticker": ticker, "strategy": "sma"},
            "result": backtest_result
        })
        
        # Calculate reward from backtest (for PPO router)
        reward = ppo_router.calculate_reward(backtest_result)
        
        tool_call_annotation = f"""<tool_call>
å·²è°ƒç”¨å·¥å…·:
1. backtest_strategy({ticker}) - å†å²å›æµ‹åˆ†æ

å·¥å…·è¿”å›çš„å›æµ‹ç»“æœ:
{json.dumps(backtest_result, ensure_ascii=False)}
</tool_call>

"""
        
        # Judge scoring based on backtest
        prompt = f"""{tool_call_annotation}ä½ æ˜¯Judgeæ™ºèƒ½ä½“ï¼ˆL3å±‚ï¼‰ï¼Œè´Ÿè´£åŸºäºå†å²å›æµ‹ç»“æœå¯¹æŠ•èµ„å»ºè®®è¿›è¡Œæœ€ç»ˆè¯„åˆ†ã€‚

è‚¡ç¥¨ä»£ç : {ticker}

Traderå»ºè®®: {recommendation}
Traderæ¨ç†: {trader_prediction.get('reasoning', '')[:500]}

å†å²å›æµ‹ç»“æœï¼ˆå·¥å…·è¿”å›ï¼‰:
- Sharpeæ¯”ç‡: {backtest_result.get('sharpe_strategy', 0):.3f}
- æ€»æ”¶ç›Šç‡: {backtest_result.get('total_return', 0):.2f}%
- äº¤æ˜“æ¬¡æ•°: {backtest_result.get('trades', 0)}

è¯·åŸºäºå›æµ‹æ•°æ®è¯„ä¼°:
1. æŠ•èµ„å»ºè®®çš„è´¨é‡è¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
2. å›æµ‹æ”¯æŒçš„è¯æ®
3. æœ€ç»ˆå†³ç­–ï¼ˆä¹°å…¥/æŒæœ‰/å–å‡ºï¼‰
4. ç½®ä¿¡åº¦è¯„ä¼°

ç”¨ä¸­æ–‡å›ç­”ï¼Œç»™å‡ºæ˜ç¡®çš„è¯„åˆ†å’Œå†³ç­–ã€‚"""
        
        response = llm.invoke([HumanMessage(content=prompt)])
        
        # Guardrail validation
        validated_message = guardrail_validator.enforce_tool_call(
            "Judge", response.content, tool_calls
        )
        is_valid, validation_result = guardrail_validator.validate_agent_message(
            "Judge", validated_message, tool_calls
        )
        
        # Extract score from response
        score_match = re.search(r'(\d+)\s*åˆ†', validated_message)
        score = int(score_match.group(1)) if score_match else 70
        
        judge_score = {
            "score": score,
            "reasoning": validated_message,
            "backtest_sharpe": backtest_result.get("sharpe_strategy", 0),
            "backtest_return": backtest_result.get("total_return", 0),
            "reward": reward,
            "timestamp": datetime.now().isoformat(),
            "tool_calls": tool_calls,
            "validation": validation_result
        }
        
        state["judge_score"] = judge_score
        state["backtest_result"] = backtest_result
        state["tool_calls"] = state.get("tool_calls", []) + tool_calls
        state["validation_results"] = state.get("validation_results", []) + [validation_result]
        
        # Update PPO router with reward
        action_history = state.get("debate_log", [])
        ppo_router.update_policy(reward, action_history)
        
        # L3 log entry
        l3_entry = {
            "round": state["round"],
            "layer": "L3",
            "agent": "Judge",
            "action": "backtest_scoring",
            "content": validated_message[:500] + "...",
            "score": score,
            "reward": reward,
            "validation": validation_result,
            "tool_calls": tool_calls
        }
        state["debate_log"] = state.get("debate_log", []) + [l3_entry]
        
    except Exception as e:
        state["judge_score"] = {"error": str(e)}
        state["debate_log"].append({
            "round": state["round"],
            "agent": "Judge",
            "action": "error",
            "content": str(e)
        })
    
    return state

def supervisor_agent(state: DebateState) -> DebateState:
    """
    Supervisor Agent: Route debate using PPO router (Backtest-Guided Router)
    Coordinates hierarchical debate: L1 (Analystâ†”Risk) â†’ L2 (Trader) â†’ L3 (Judge)
    """
    llm = get_llm(temperature=0.6)
    if not llm:
        return state
    
    ticker = state["ticker"]
    query = state["query"]
    round_num = state["round"]
    
    # Use PPO router for routing decision
    current_state = {
        "round": round_num,
        "max_rounds": state.get("max_rounds", 3),
        "ticker": ticker
    }
    available_agents = ["Analyst", "Risk", "Trader", "Judge"]
    routing_decision = ppo_router.route_decision(current_state, available_agents)
    
    # Collect all agent outputs
    analyst_evidence = state.get("analyst_evidence", {})
    risk_flags = state.get("risk_flags", [])
    trader_prediction = state.get("trader_prediction", {})
    judge_score = state.get("judge_score", {})
    
    if round_num < state["max_rounds"]:
        # Continue debate
        prompt = f"""ä½ æ˜¯ç›‘ç£è€…ï¼Œåè°ƒå¤šæ™ºèƒ½ä½“è¾©è®ºã€‚å½“å‰æ˜¯ç¬¬ {round_num} è½®è¾©è®ºã€‚

è‚¡ç¥¨ä»£ç : {ticker}
ç”¨æˆ·æŸ¥è¯¢: {query}

åˆ†æå¸ˆè¯æ®: {json.dumps(analyst_evidence, ensure_ascii=False)[:800]}
é£é™©æ ‡å¿—: {risk_flags}
äº¤æ˜“å‘˜é¢„æµ‹: {json.dumps(trader_prediction, ensure_ascii=False)[:800]}

è¯·è¯„ä¼°æ˜¯å¦éœ€è¦ç»§ç»­è¾©è®ºï¼Œæˆ–å¯ä»¥åšå‡ºæœ€ç»ˆç»¼åˆåˆ¤æ–­ã€‚"""
        
        response = llm.invoke([HumanMessage(content=prompt)])
        
        state["round"] += 1
        state["debate_log"].append({
            "round": round_num,
            "agent": "Supervisor",
            "action": "synthesis",
            "content": response.content[:500] + "..."
        })
    else:
        # Final synthesis
        prompt = f"""ä½ æ˜¯ç›‘ç£è€…ï¼Œè¿›è¡Œæœ€ç»ˆç»¼åˆåˆ¤æ–­ã€‚å·²å®Œæˆ {state['max_rounds']} è½®è¾©è®ºã€‚

è‚¡ç¥¨ä»£ç : {ticker}
ç”¨æˆ·æŸ¥è¯¢: {query}

æ‰€æœ‰è¯æ®:
- åˆ†æå¸ˆ: {json.dumps(analyst_evidence, ensure_ascii=False)[:1000]}
- é£é™©: {risk_flags}
- äº¤æ˜“å‘˜: {json.dumps(trader_prediction, ensure_ascii=False)[:1000]}

è¯·æä¾›æœ€ç»ˆç»¼åˆæŠ¥å‘Šï¼ŒåŒ…æ‹¬:
1. ç»¼åˆæ‰€æœ‰æ™ºèƒ½ä½“çš„è§‚ç‚¹
2. æœ€ç»ˆæŠ•èµ„å»ºè®®
3. å…³é”®é£é™©å’Œæœºä¼š
4. ç½®ä¿¡åº¦è¯„ä¼°

ç”¨ä¸­æ–‡å›ç­”ï¼Œç»™å‡ºæ¸…æ™°æ˜ç¡®çš„ç»“è®ºã€‚"""
        
        response = llm.invoke([HumanMessage(content=prompt)])
        state["final_synthesis"] = response.content
        state["debate_log"].append({
            "round": round_num,
            "agent": "Supervisor",
            "action": "final_synthesis",
            "content": response.content
        })
    
    return state

def should_continue(state: DebateState) -> str:
    """Decide whether to continue debate or end"""
    if state["round"] >= state["max_rounds"]:
        return "end"
    return "continue"

# ============================================================================
# LangGraph Construction
# ============================================================================

def create_debate_graph(use_debate: str = "debate"):
    """
    Create LangGraph workflow for hierarchical multi-agent debate
    
    Args:
        use_debate: "debate" (full hierarchical), "no_debate" (direct), "single_agent" (ablation)
    """
    workflow = StateGraph(DebateState)
    
    if use_debate == "debate":
        # Hierarchical debate flow: L1 (Analystâ†”Risk) â†’ L2 (Trader) â†’ L3 (Judge)
        workflow.add_node("analyst", analyst_agent)
        workflow.add_node("risk", risk_agent)
        workflow.add_node("trader", trader_agent)
        workflow.add_node("judge", judge_agent)
        workflow.add_node("supervisor", supervisor_agent)
        
        # Hierarchical flow
        workflow.set_entry_point("analyst")
        workflow.add_edge("analyst", "risk")  # L1: Analyst â†’ Risk
        workflow.add_edge("risk", "trader")    # L1 â†’ L2: Trader synthesis
        workflow.add_edge("trader", "judge")  # L2 â†’ L3: Judge scoring
        workflow.add_edge("judge", "supervisor")  # L3 â†’ Supervisor routing
        
        # Conditional edge from supervisor (PPO-guided)
        workflow.add_conditional_edges(
            "supervisor",
            should_continue,
            {
                "continue": "analyst",  # Loop back for next round (PPO decides)
                "end": END
            }
        )
    elif use_debate == "no_debate":
        # Direct synthesis without debate (ablation)
        def direct_analysis(state: DebateState) -> DebateState:
            state = analyst_agent(state)
            state = risk_agent(state)
            state = trader_agent(state)
            # Simple synthesis without judge
            llm = get_llm()
            if llm:
                synthesis = llm.invoke([HumanMessage(
                    content=f"ç»¼åˆåˆ†æå¸ˆã€é£é™©å’Œäº¤æ˜“å‘˜çš„è§‚ç‚¹ï¼Œç»™å‡ºæœ€ç»ˆå»ºè®®ã€‚\n"
                    f"åˆ†æå¸ˆ: {state.get('analyst_evidence', {})}\n"
                    f"é£é™©: {state.get('risk_flags', [])}\n"
                    f"äº¤æ˜“å‘˜: {state.get('trader_prediction', {})}"
                )])
                state["final_synthesis"] = synthesis.content
            return state
        
        workflow.add_node("direct", direct_analysis)
        workflow.set_entry_point("direct")
        workflow.add_edge("direct", END)
    else:  # single_agent
        # Single agent ablation (only analyst)
        workflow.add_node("analyst", analyst_agent)
        workflow.set_entry_point("analyst")
        workflow.add_edge("analyst", END)
    
    return workflow.compile(checkpointer=MemorySaver())

# ============================================================================
# Metrics Calculation for Ablation Study
# ============================================================================

def calculate_ablation_metrics(analysis: Dict[str, Any]) -> Dict[str, float]:
    """
    Calculate metrics for ablation study comparison
    Returns: Sharpe ratio, MAE (Mean Absolute Error), confidence score
    """
    metrics = {}
    
    # Get financial metrics
    analyst_evidence = analysis.get("analyst_evidence", {})
    financial_metrics = analyst_evidence.get("metrics", {})
    
    # Sharpe Ratio
    sharpe = financial_metrics.get("Sharpe", 0.0)
    metrics["Sharpe"] = sharpe
    
    # MAE: Compare predicted vs actual (if available)
    trader_prediction = analysis.get("trader_prediction", {})
    growth_pred = trader_prediction.get("growth_prediction", {})
    
    # Calculate MAE from prediction confidence
    if isinstance(growth_pred, dict):
        confidence = growth_pred.get("confidence", 0.5)
        mae = 1.0 - confidence  # Lower confidence = higher error
        metrics["MAE"] = mae
    else:
        metrics["MAE"] = 0.5  # Default
    
    # Hallucination confidence
    hallucination_check = analysis.get("hallucination_check", {})
    if isinstance(hallucination_check, dict):
        metrics["HallucinationConfidence"] = hallucination_check.get("confidence", 0.5)
    else:
        metrics["HallucinationConfidence"] = 0.5
    
    # Overall quality score
    metrics["QualityScore"] = (sharpe / 3.0 + (1 - metrics["MAE"]) + metrics["HallucinationConfidence"]) / 3.0
    
    return metrics

# ============================================================================
# Streamlit UI Components
# ============================================================================

def render_sidebar():
    """Render sidebar with input controls"""
    with st.sidebar:
        st.title("ğŸ“Š DebateFin é…ç½®")
        
        # Ticker input
        ticker = st.text_input(
            "è‚¡ç¥¨ä»£ç ",
            value="600519",
            help="è¾“å…¥è‚¡ç¥¨ä»£ç ï¼Œå¦‚ï¼š600519 (èŒ…å°), AAPL (è‹¹æœ)"
        )
        
        # Query input
        query = st.text_area(
            "åˆ†ææŸ¥è¯¢",
            value="é¢„æµ‹2026å¹´ROEå’ŒæŠ•èµ„å»ºè®®",
            height=100,
            help="è¾“å…¥ä½ çš„åˆ†æéœ€æ±‚"
        )
        
        
        st.divider()
        st.markdown("### ğŸ”¬  æ¶ˆèç ”ç©¶")
        
        debate_mode = st.radio(
            "è¾©è®ºæ¨¡å¼",
            options=["debate", "no_debate", "single_agent"],
            format_func=lambda x: {
                "debate": "âœ… å®Œæ•´åˆ†å±‚è¾©è®º (L1â†’L2â†’L3)",
                "no_debate": "â¸ï¸ æ— è¾©è®ºç›´æ¥ç»¼åˆ",
                "single_agent": "ğŸ”¬ å•æ™ºèƒ½ä½“ (Analyst only)"
            }[x],
            index=0,
            help="é€‰æ‹©ä¸åŒçš„è¾©è®ºæ¨¡å¼è¿›è¡Œæ¶ˆèç ”ç©¶"
        )
        
        run_ablation = st.checkbox(
            "è¿è¡Œæ¶ˆèå¯¹æ¯”å®éªŒ",
            value=False,
            help="åŒæ—¶è¿è¡Œæœ‰/æ— è¾©è®ºç‰ˆæœ¬ï¼Œå¯¹æ¯”Sharpe/MAEæŒ‡æ ‡"
        )
        
        # Max rounds
        max_rounds = st.slider(
            "æœ€å¤§è¾©è®ºè½®æ•°",
            min_value=1,
            max_value=3,
            value=3,
            help="æœ€å¤šè¿›è¡Œå‡ è½®è¾©è®º"
        )
        
        st.divider()
        
        # Action buttons
        col1, col2 = st.columns(2)
        with col1:
            analyze_btn = st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True)
        with col2:
            clear_btn = st.button("ğŸ—‘ï¸ æ¸…é™¤", use_container_width=True)
        
        if clear_btn:
            st.session_state.conversation_history = []
            st.session_state.debate_logs = []
            st.session_state.current_analysis = None
            st.rerun()
        
        st.divider()
        st.markdown("### ğŸ“ˆ å…³äº DebateFin")
        st.markdown("""
        **DebateFin** æ˜¯ä¸€ä¸ªå¯ä¿¡èµ–çš„å¤šæ™ºèƒ½ä½“é‡‘èåˆ†æç³»ç»Ÿï¼š
        
        - ğŸ¤– **å¤šæ™ºèƒ½ä½“æ¶æ„**: Analyst, Risk, Trader
        - ğŸ’¬ **ç»“æ„åŒ–è¾©è®º**: è¯æ®-åé©³-ç»¼åˆ
        - ğŸ“Š **å·¥å…·æ¥åœ°**: é¿å…LLMå¹»è§‰
        - ğŸ”¬ **æ¶ˆèç ”ç©¶**: å¯¹æ¯”æœ‰/æ— è¾©è®ºæ•ˆæœ
        """)
        
        return ticker, query, debate_mode, max_rounds, run_ablation, analyze_btn

def render_debate_logs(logs: List[Dict]):
    """Render debate logs in expandable sections with hierarchical tree view"""
    if not logs:
        return
    
    st.subheader("ğŸ’¬ è¾©è®ºæ—¥å¿—ï¼ˆåˆ†å±‚æ ‘çŠ¶è§†å›¾ï¼‰")
    
    # Group by layer for hierarchical view
    l1_logs = [log for log in logs if log.get("layer") == "L1"]
    l2_logs = [log for log in logs if log.get("layer") == "L2"]
    l3_logs = [log for log in logs if log.get("layer") == "L3"]
    
    # L1 Layer: Analyst â†” Risk
    if l1_logs:
        with st.expander("ğŸ”µ L1å±‚: åŸºæœ¬é¢åˆ†æ (Analyst â†” Risk)", expanded=True):
            for log_entry in l1_logs:
                agent_name = log_entry.get("agent", "Unknown")
                action = log_entry.get("action", "")
                content = log_entry.get("content", "")
                round_num = log_entry.get("round", 0)
                
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"**{agent_name}** (ç¬¬{round_num}è½®): {action}")
                with col2:
                    if "validation" in log_entry:
                        val = log_entry["validation"]
                        if val.get("has_tool_call"):
                            st.success("âœ… å·¥å…·è°ƒç”¨")
                        else:
                            st.error("âŒ ç¼ºå°‘å·¥å…·è°ƒç”¨")
                
                st.markdown(f"*{content}*")
                
                # Show tool calls
                if "tool_calls" in log_entry:
                    with st.expander(f"æŸ¥çœ‹{agent_name}çš„å·¥å…·è°ƒç”¨", expanded=False):
                        for tc in log_entry["tool_calls"]:
                            st.code(f"{tc.get('tool', 'unknown')}: {tc.get('result', {})}")
                
                st.divider()
    
    # L2 Layer: Trader Synthesis
    if l2_logs:
        with st.expander("ğŸŸ¢ L2å±‚: äº¤æ˜“å†³ç­– (Traderç»¼åˆ)", expanded=True):
            for log_entry in l2_logs:
                agent_name = log_entry.get("agent", "Unknown")
                content = log_entry.get("content", "")
                recommendation = log_entry.get("recommendation", "")
                
                st.markdown(f"**{agent_name}**: {recommendation}")
                st.markdown(f"*{content}*")
                
                if "tool_calls" in log_entry:
                    with st.expander("æŸ¥çœ‹Traderçš„å·¥å…·è°ƒç”¨", expanded=False):
                        for tc in log_entry["tool_calls"]:
                            st.code(f"{tc.get('tool', 'unknown')}: {tc.get('result', {})}")
                
                st.divider()
    
    # L3 Layer: Judge Scoring
    if l3_logs:
        with st.expander("ğŸ”´ L3å±‚: å›æµ‹è¯„åˆ† (Judge)", expanded=True):
            for log_entry in l3_logs:
                agent_name = log_entry.get("agent", "Unknown")
                content = log_entry.get("content", "")
                score = log_entry.get("score", 0)
                reward = log_entry.get("reward", 0)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("è¯„åˆ†", f"{score}/100")
                with col2:
                    st.metric("å›æµ‹å¥–åŠ±", f"{reward:.3f}")
                with col3:
                    if "validation" in log_entry:
                        val = log_entry["validation"]
                        st.metric("éªŒè¯é€šè¿‡", "âœ…" if val.get("has_tool_call") else "âŒ")
                
                st.markdown(f"*{content}*")
                
                if "tool_calls" in log_entry:
                    with st.expander("æŸ¥çœ‹Judgeçš„å›æµ‹ç»“æœ", expanded=False):
                        for tc in log_entry["tool_calls"]:
                            result = tc.get("result", {})
                            st.json(result)
                
                st.divider()
    
    # Fallback: Show all logs if no layer grouping
    if not (l1_logs or l2_logs or l3_logs):
        for i, log_entry in enumerate(logs):
            agent_name = log_entry.get("agent", "Unknown")
            action = log_entry.get("action", "")
            content = log_entry.get("content", "")
            round_num = log_entry.get("round", 0)
            
            with st.expander(f"ç¬¬ {round_num} è½® - {agent_name} ({action})", expanded=(i == len(logs) - 1)):
                st.markdown(f"**æ“ä½œ**: {action}")
                st.markdown(f"**å†…å®¹**: {content}")
                if "recommendation" in log_entry:
                    st.info(f"**å»ºè®®**: {log_entry['recommendation']}")
                if "sentiment_score" in log_entry:
                    st.metric("å¸‚åœºæƒ…ç»ªå¾—åˆ†", f"{log_entry['sentiment_score']:.2f}")

def render_financial_charts(analysis: Dict):
    """Render financial analysis charts"""
    st.subheader("ğŸ“Š è´¢åŠ¡åˆ†æå›¾è¡¨")
    
    analyst_evidence = analysis.get("analyst_evidence", {})
    metrics = analyst_evidence.get("metrics", {})
    trader_prediction = analysis.get("trader_prediction", {})
    
    if not metrics:
        st.warning("æš‚æ— è´¢åŠ¡æ•°æ®")
        return
    
    # Create charts
    col1, col2 = st.columns(2)
    
    with col1:
        # ROE Chart
        if "ROE" in metrics:
            fig, ax = plt.subplots(figsize=(8, 5))
            roe_value = metrics.get("ROE", 0)
            ax.barh(["ROE"], [roe_value], color='green' if roe_value > 0.15 else 'orange')
            ax.set_xlabel("ROE (%)")
            ax.set_title("å‡€èµ„äº§æ”¶ç›Šç‡ (ROE)")
            ax.axvline(x=0.15, color='r', linestyle='--', label='åŸºå‡†çº¿ (15%)')
            ax.legend()
            st.pyplot(fig)
            plt.close()
    
    with col2:
        # Sharpe Ratio Chart
        if "Sharpe" in metrics:
            fig, ax = plt.subplots(figsize=(8, 5))
            sharpe_value = metrics.get("Sharpe", 0)
            ax.barh(["Sharpeæ¯”ç‡"], [sharpe_value], color='blue' if sharpe_value > 1 else 'red')
            ax.set_xlabel("Sharpeæ¯”ç‡")
            ax.set_title("é£é™©è°ƒæ•´åæ”¶ç›Š (Sharpe Ratio)")
            ax.axvline(x=1, color='g', linestyle='--', label='åŸºå‡†çº¿ (1.0)')
            ax.legend()
            st.pyplot(fig)
            plt.close()
    
    # Growth Prediction Chart
    if trader_prediction and "growth_prediction" in trader_prediction:
        growth_pred = trader_prediction["growth_prediction"]
        if isinstance(growth_pred, dict) and "forecast" in growth_pred:
            fig, ax = plt.subplots(figsize=(10, 6))
            forecast_data = growth_pred["forecast"]
            if isinstance(forecast_data, (list, np.ndarray)):
                ax.plot(forecast_data, marker='o', label='é¢„æµ‹å¢é•¿')
                ax.set_xlabel("æ—¶é—´æ­¥")
                ax.set_ylabel("å¢é•¿ç‡ (%)")
                ax.set_title("LSTMå¢é•¿é¢„æµ‹")
                ax.grid(True, alpha=0.3)
                ax.legend()
                st.pyplot(fig)
                plt.close()

def render_backtest_results(ticker: str):
    """Render backtesting results with Plotly interactive charts (ä½¿ç”¨ç¼“å­˜ï¼Œé˜²æ­¢é¢‘ç¹è¯·æ±‚)"""
    st.subheader("ğŸ“ˆ å›æµ‹ç»“æœ (5å¹´æ•°æ®)")
    
    try:
        # ä½¿ç”¨ç¼“å­˜å‡½æ•°è·å–ä»·æ ¼å†å²ï¼ˆé˜²æ­¢é¢‘ç¹è¯·æ±‚è¢«é™æµï¼‰
        prices = get_price_history(ticker, period="5y")
        
        if prices.empty or len(prices) < 200:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°æ®æºå¤±è´¥
            if prices.empty:
                st.warning(f"âš ï¸ æ— æ³•è·å–è‚¡ç¥¨ {ticker} çš„å†å²æ•°æ®ã€‚è¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ç¨åå†è¯•ã€‚")
            else:
                st.warning(f"âš ï¸ è·å–çš„å†å²æ•°æ®ä¸è¶³ï¼ˆä»… {len(prices)} æ¡ï¼‰ï¼Œæ— æ³•è¿›è¡Œå›æµ‹åˆ†æã€‚")
            return
        
        # è½¬æ¢ä¸º DataFrame æ ¼å¼ä»¥ä¾¿åç»­å¤„ç†
        hist = pd.DataFrame({'Close': prices})
        hist.index = prices.index
        
        # Simple moving average strategy
        hist['SMA_50'] = hist['Close'].rolling(window=50).mean()
        hist['SMA_200'] = hist['Close'].rolling(window=200).mean()
        
        # Calculate returns
        hist['Returns'] = hist['Close'].pct_change()
        cumulative_returns = (1 + hist['Returns']).cumprod()
        
        # Use Plotly for interactive charts if available
        if PLOTLY_AVAILABLE:
            # Create subplots
            fig = make_subplots(
                rows=2, cols=1,
                subplot_titles=(f"{ticker} ä»·æ ¼èµ°åŠ¿ (5å¹´)", "ç´¯è®¡æ”¶ç›Šç‡"),
                vertical_spacing=0.1,
                row_heights=[0.6, 0.4]
            )
            
            # Price and moving averages
            fig.add_trace(
                go.Scatter(x=hist.index, y=hist['Close'], name='æ”¶ç›˜ä»·', line=dict(width=2)),
                row=1, col=1
            )
            fig.add_trace(
                go.Scatter(x=hist.index, y=hist['SMA_50'], name='SMA 50', line=dict(dash='dash')),
                row=1, col=1
            )
            fig.add_trace(
                go.Scatter(x=hist.index, y=hist['SMA_200'], name='SMA 200', line=dict(dash='dot')),
                row=1, col=1
            )
            
            # Cumulative returns
            fig.add_trace(
                go.Scatter(x=cumulative_returns.index, y=cumulative_returns.values, 
                          name='ç´¯è®¡æ”¶ç›Š', line=dict(color='green', width=2)),
                row=2, col=1
            )
            fig.add_hline(y=1, line_dash="dash", line_color="red", annotation_text="åŸºå‡†çº¿", row=2, col=1)
            
            # Update layout
            fig.update_layout(height=700, showlegend=True, title_text=f"{ticker} å›æµ‹åˆ†æ")
            fig.update_xaxes(title_text="æ—¥æœŸ", row=2, col=1)
            fig.update_yaxes(title_text="ä»·æ ¼", row=1, col=1)
            fig.update_yaxes(title_text="ç´¯è®¡æ”¶ç›Šå€æ•°", row=2, col=1)
            
            # ä½¿ç”¨ ticker å’Œæ—¶é—´æˆ³ç¡®ä¿ key å”¯ä¸€
            import time
            unique_key = f"plotly_backtest_{ticker}_{int(time.time() * 1000)}"
            st.plotly_chart(fig, use_container_width=True, key=unique_key)
        else:
            # Fallback to matplotlib
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
            ax1.plot(hist.index, hist['Close'], label='æ”¶ç›˜ä»·', linewidth=2)
            ax1.plot(hist.index, hist['SMA_50'], label='SMA 50', alpha=0.7)
            ax1.plot(hist.index, hist['SMA_200'], label='SMA 200', alpha=0.7)
            ax1.set_title(f"{ticker} ä»·æ ¼èµ°åŠ¿ (5å¹´)")
            ax1.set_ylabel("ä»·æ ¼")
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            ax2.plot(cumulative_returns.index, cumulative_returns.values, label='ç´¯è®¡æ”¶ç›Š', color='green', linewidth=2)
            ax2.axhline(y=1, color='r', linestyle='--', label='åŸºå‡†çº¿')
            ax2.set_title("ç´¯è®¡æ”¶ç›Šç‡")
            ax2.set_ylabel("ç´¯è®¡æ”¶ç›Šå€æ•°")
            ax2.set_xlabel("æ—¥æœŸ")
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
        
        # Metrics
        total_return = (cumulative_returns.iloc[-1] - 1) * 100
        volatility = hist['Returns'].std() * np.sqrt(252) * 100
        sharpe = (hist['Returns'].mean() * 252) / (hist['Returns'].std() * np.sqrt(252)) if hist['Returns'].std() > 0 else 0
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€»æ”¶ç›Šç‡", f"{total_return:.2f}%")
        with col2:
            st.metric("å¹´åŒ–æ³¢åŠ¨ç‡", f"{volatility:.2f}%")
        with col3:
            st.metric("Sharpeæ¯”ç‡", f"{sharpe:.2f}")
            
    except Exception as e:
        st.error(f"å›æµ‹å¤±è´¥: {str(e)}")

def render_ablation_comparison(with_debate: Dict, without_debate: Dict):
    """
    æ¸²æŸ“æ¶ˆèç ”ç©¶å¯¹æ¯”ï¼ˆä½¿ç”¨å”¯ä¸€çš„ key é¿å…é‡å¤ï¼‰
    """
    st.subheader("ğŸ”¬ æ¶ˆèç ”ç©¶å¯¹æ¯” (æœ‰è¾©è®º vs æ— è¾©è®º)")
    
    # ä½¿ç”¨ session state è®¡æ•°å™¨ç¡®ä¿ key å”¯ä¸€
    if 'ablation_chart_counter' not in st.session_state:
        st.session_state.ablation_chart_counter = 0
    st.session_state.ablation_chart_counter += 1
    
    # Calculate metrics for both (use cached if available)
    metrics_with = with_debate.get("metrics", calculate_ablation_metrics(with_debate))
    metrics_without = without_debate.get("metrics", calculate_ablation_metrics(without_debate))
    
    # Comparison metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        sharpe_diff = metrics_with["Sharpe"] - metrics_without["Sharpe"]
        st.metric("Sharpeæ¯”ç‡å·®å¼‚", f"{sharpe_diff:.3f}", 
                 delta=f"{metrics_with['Sharpe']:.3f} vs {metrics_without['Sharpe']:.3f}")
    
    with col2:
        mae_diff = metrics_with["MAE"] - metrics_without["MAE"]
        st.metric("MAEå·®å¼‚", f"{mae_diff:.3f}",
                 delta=f"{metrics_with['MAE']:.3f} vs {metrics_without['MAE']:.3f}")
    
    with col3:
        conf_diff = metrics_with["HallucinationConfidence"] - metrics_without["HallucinationConfidence"]
        st.metric("å¹»è§‰ç½®ä¿¡åº¦å·®å¼‚", f"{conf_diff:.3f}",
                 delta=f"{metrics_with['HallucinationConfidence']:.3f} vs {metrics_without['HallucinationConfidence']:.3f}")
    
    with col4:
        quality_diff = metrics_with["QualityScore"] - metrics_without["QualityScore"]
        st.metric("è´¨é‡å¾—åˆ†å·®å¼‚", f"{quality_diff:.3f}",
                 delta=f"{metrics_with['QualityScore']:.3f} vs {metrics_without['QualityScore']:.3f}")
    
    # Side-by-side charts
    metrics_list = ["Sharpe", "MAE", "HallucinationConfidence", "QualityScore"]
    
    if PLOTLY_AVAILABLE:
        fig = make_subplots(
            rows=1, cols=2,
            subplot_titles=("æœ‰è¾©è®º", "æ— è¾©è®º"),
            specs=[[{"type": "bar"}, {"type": "bar"}]]
        )
        
        fig.add_trace(
            go.Bar(x=metrics_list, y=[metrics_with[m] for m in metrics_list], 
                   name="æœ‰è¾©è®º", marker_color='blue', showlegend=False),
            row=1, col=1
        )
        
        fig.add_trace(
            go.Bar(x=metrics_list, y=[metrics_without[m] for m in metrics_list],
                   name="æ— è¾©è®º", marker_color='orange', showlegend=False),
            row=1, col=2
        )
        
        fig.update_layout(height=400, showlegend=False, title_text="æŒ‡æ ‡å¯¹æ¯”")
        fig.update_yaxes(title_text="æ•°å€¼", row=1, col=1)
        fig.update_yaxes(title_text="æ•°å€¼", row=1, col=2)
        
        # ä½¿ç”¨è®¡æ•°å™¨ç¡®ä¿ key å”¯ä¸€ï¼ˆé¿å…åŒä¸€é¡µé¢å¤šæ¬¡è°ƒç”¨å¯¼è‡´é‡å¤ï¼‰
        unique_key = f"plotly_ablation_{st.session_state.ablation_chart_counter}"
        st.plotly_chart(fig, use_container_width=True, key=unique_key)
    else:
        # Fallback to matplotlib
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
        
        x = np.arange(len(metrics_list))
        width = 0.35
        
        ax1.bar(x, [metrics_with[m] for m in metrics_list], width, label='æœ‰è¾©è®º', color='blue')
        ax1.set_title("æœ‰è¾©è®º")
        ax1.set_xticks(x)
        ax1.set_xticklabels(metrics_list, rotation=45)
        ax1.set_ylabel("æ•°å€¼")
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        ax2.bar(x, [metrics_without[m] for m in metrics_list], width, label='æ— è¾©è®º', color='orange')
        ax2.set_title("æ— è¾©è®º")
        ax2.set_xticks(x)
        ax2.set_xticklabels(metrics_list, rotation=45)
        ax2.set_ylabel("æ•°å€¼")
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()
    
    # Store results
    st.session_state.ablation_results = {
        "with_debate": metrics_with,
        "without_debate": metrics_without
    }

def render_final_recommendation(analysis: Dict):
    """Render final investment recommendation"""
    st.subheader("ğŸ¯ æœ€ç»ˆæŠ•èµ„å»ºè®®")
    
    trader_prediction = analysis.get("trader_prediction", {})
    final_synthesis = analysis.get("final_synthesis", "")
    risk_flags = analysis.get("risk_flags", [])
    
    # Recommendation badge
    recommendation = trader_prediction.get("recommendation", "æŒæœ‰")
    if recommendation == "ä¹°å…¥":
        st.success(f"âœ… **å»ºè®®: {recommendation}**")
    elif recommendation == "å–å‡º":
        st.error(f"âŒ **å»ºè®®: {recommendation}**")
    else:
        st.info(f"â¸ï¸ **å»ºè®®: {recommendation}**")
    
    # Risk flags
    if risk_flags:
        st.warning(f"âš ï¸ **é£é™©æç¤º**: {', '.join(risk_flags)}")
    
    # Final synthesis
    if final_synthesis:
        st.markdown("### ğŸ“ ç»¼åˆæŠ¥å‘Š")
        st.markdown(final_synthesis)
    
    # Reasoning
    if "reasoning" in trader_prediction:
        st.markdown("### ğŸ’¡ æŠ•èµ„é€»è¾‘")
        st.markdown(trader_prediction["reasoning"])

# ============================================================================
# Main App
# ============================================================================

def main():
    """Main Streamlit application"""
    st.title("ğŸ“Š DebateFin: å¯ä¿¡èµ–çš„å¤šæ™ºèƒ½ä½“é‡‘èåˆ†æç³»ç»Ÿ")
    st.markdown("**helloaisvg Demo** - ç»“æ„åŒ–è¾©è®ºå‡å°‘é‡‘èæ¨ç†ä¸­çš„å¹»è§‰")
    
    # Sidebar
    ticker, query, debate_mode, max_rounds, run_ablation, analyze_btn = render_sidebar()
    
    # Main content area
    if analyze_btn:
        if not ticker:
            st.error("è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ")
            return
        
        # Clear previous hallucination checks
        st.session_state.hallucination_checks = []
        
        if run_ablation:
            # Run ablation study: both with and without debate
            with st.spinner("ğŸ”¬ è¿è¡Œæ¶ˆèç ”ç©¶ï¼šåŒæ—¶åˆ†ææœ‰/æ— è¾©è®ºç‰ˆæœ¬..."):
                try:
                    # Run with debate
                    initial_state_with = DebateState(
                        messages=[], ticker=ticker, query=query, round=1,
                        max_rounds=max_rounds, analyst_evidence={}, risk_flags=[],
                        trader_prediction={}, debate_log=[], final_synthesis="",
                        use_debate="debate", metrics={}, hallucination_check={},
                        l1_debate_log=[], l2_synthesis="", judge_score={}, backtest_result={},
                        tool_calls=[], validation_results=[]
                    )
                    graph_with = create_debate_graph(use_debate="debate")
                    final_state_with = graph_with.invoke(initial_state_with, {"configurable": {"thread_id": "with"}})
                    final_state_with["metrics"] = calculate_ablation_metrics(final_state_with)
                    
                    # Run without debate
                    initial_state_without = DebateState(
                        messages=[], ticker=ticker, query=query, round=1,
                        max_rounds=1, analyst_evidence={}, risk_flags=[],
                        trader_prediction={}, debate_log=[], final_synthesis="",
                        use_debate="no_debate", metrics={}, hallucination_check={},
                        l1_debate_log=[], l2_synthesis="", judge_score={}, backtest_result={},
                        tool_calls=[], validation_results=[]
                    )
                    graph_without = create_debate_graph(use_debate="no_debate")
                    final_state_without = graph_without.invoke(initial_state_without, {"configurable": {"thread_id": "without"}})
                    final_state_without["metrics"] = calculate_ablation_metrics(final_state_without)
                    
                    # Store both results
                    st.session_state.current_analysis = final_state_with
                    st.session_state.ablation_results = {
                        "with_debate": final_state_with,
                        "without_debate": final_state_without
                    }
                    st.session_state.debate_logs = final_state_with.get("debate_log", [])
                    
                    st.success("âœ… æ¶ˆèç ”ç©¶å®Œæˆï¼")
                    
                except Exception as e:
                    st.error(f"æ¶ˆèç ”ç©¶è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                    st.exception(e)
                    return
        else:
            # Normal single run
            initial_state = DebateState(
                messages=[], ticker=ticker, query=query, round=1,
                max_rounds=max_rounds, analyst_evidence={}, risk_flags=[],
                trader_prediction={}, debate_log=[], final_synthesis="",
                use_debate=debate_mode, metrics={}, hallucination_check={},
                l1_debate_log=[], l2_synthesis="", judge_score={}, backtest_result={},
                tool_calls=[], validation_results=[]
            )
            
            with st.spinner("ğŸ¤– å¤šæ™ºèƒ½ä½“æ­£åœ¨åˆ†æä¸­ï¼Œè¯·ç¨å€™..."):
                try:
                    graph = create_debate_graph(use_debate=debate_mode)
                    config = {"configurable": {"thread_id": "1"}}
                    
                    final_state = graph.invoke(initial_state, config=config)
                    final_state["metrics"] = calculate_ablation_metrics(final_state)
                    
                    st.session_state.current_analysis = final_state
                    st.session_state.debate_logs = final_state.get("debate_log", [])
                    
                    st.success("âœ… åˆ†æå®Œæˆï¼")
                    
                except Exception as e:
                    st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                    st.exception(e)
                    return
    
    # Display results
    if st.session_state.current_analysis:
        analysis = st.session_state.current_analysis
        
        # Show ablation comparison if available (åªåœ¨ä¸»é¡µé¢æ˜¾ç¤ºä¸€æ¬¡ï¼Œé¿å…é‡å¤)
        # æ³¨æ„ï¼šåœ¨ tabs ä¸­ä¹Ÿä¼šæ˜¾ç¤ºï¼Œæ‰€ä»¥è¿™é‡Œæ³¨é‡Šæ‰ï¼Œé¿å…é‡å¤è°ƒç”¨å¯¼è‡´ key å†²çª
        # if st.session_state.ablation_results:
        #     st.markdown("---")
        #     render_ablation_comparison(
        #         st.session_state.ablation_results["with_debate"],
        #         st.session_state.ablation_results["without_debate"]
        #     )
        #     st.markdown("---")
        
        # Show hallucination checks
        if st.session_state.hallucination_checks:
            with st.expander("ğŸ” å¹»è§‰æ£€æŸ¥ç»“æœ", expanded=False):
                for check in st.session_state.hallucination_checks:
                    st.markdown(f"**{check['agent']} (ç¬¬{check['round']}è½®)**")
                    check_data = check.get("check", {})
                    if check_data.get("has_hallucination"):
                        st.warning(f"âš ï¸ æ£€æµ‹åˆ°æ½œåœ¨å¹»è§‰: {', '.join(check_data.get('issues', []))}")
                    else:
                        st.success(f"âœ… ç½®ä¿¡åº¦: {check_data.get('confidence', 0):.2f}")
        
        # Tabs for different views
        tab_names = ["ğŸ“Š ç»¼åˆåˆ†æ", "ğŸ’¬ è¾©è®ºæ—¥å¿—", "ğŸ“ˆ å›¾è¡¨åˆ†æ", "ğŸ“„ å¯¼å‡ºæŠ¥å‘Š"]
        if st.session_state.ablation_results:
            tab_names.insert(1, "ğŸ”¬ æ¶ˆèç ”ç©¶")
        
        tabs = st.tabs(tab_names)
        tab_idx = 0
        
        with tabs[tab_idx]:
            render_final_recommendation(analysis)
        tab_idx += 1
        
        if st.session_state.ablation_results:
            with tabs[tab_idx]:
                render_ablation_comparison(
                    st.session_state.ablation_results["with_debate"],
                    st.session_state.ablation_results["without_debate"]
                )
            tab_idx += 1
        
        with tabs[tab_idx]:
            render_debate_logs(st.session_state.debate_logs)
        tab_idx += 1
        
        with tabs[tab_idx]:
            render_financial_charts(analysis)
            st.divider()
            render_backtest_results(analysis.get("ticker", ""))
        tab_idx += 1
        
        with tabs[tab_idx]:
            st.subheader("ğŸ“„ å¯¼å‡ºPDFæŠ¥å‘Š")
            
            # Enhanced PDF with debate logs and ablation results
            col1, col2 = st.columns(2)
            with col1:
                include_debate_logs = st.checkbox("åŒ…å«è¾©è®ºæ—¥å¿—", value=True)
                include_ablation = st.checkbox("åŒ…å«æ¶ˆèç ”ç©¶ç»“æœ", value=bool(st.session_state.ablation_results))
            
            if st.button("ç”ŸæˆHTMLæŠ¥å‘Š", type="primary"):
                try:
                    report_data = {
                        "analysis": analysis,
                        "debate_logs": st.session_state.debate_logs if include_debate_logs else [],
                        "ablation_results": st.session_state.ablation_results if include_ablation else None,
                        "hallucination_checks": st.session_state.hallucination_checks
                    }
                    html_buffer = generate_html_report_bytes(report_data)
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½HTMLæŠ¥å‘Š",
                        data=html_buffer.getvalue(),
                        file_name=f"DebateFin_Report_{analysis.get('ticker', 'UNKNOWN')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
                        mime="text/html",
                        use_container_width=True
                    )
                    st.info('ğŸ’¡ æç¤ºï¼šä¸‹è½½HTMLæ–‡ä»¶åï¼Œå¯åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ï¼Œç„¶åä½¿ç”¨æµè§ˆå™¨çš„"æ‰“å°"åŠŸèƒ½ï¼ˆCtrl+P / Cmd+Pï¼‰å¯¼å‡ºä¸ºPDF')
                except Exception as e:
                    st.error(f"HTMLæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
                    st.exception(e)
    
    # Footer
    st.divider()
    st.markdown("""
    <div style='text-align: center; color: gray;'>
    <p>DebateFin - helloaisvg | Powered by LangChain, LangGraph & DeepSeek</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()

